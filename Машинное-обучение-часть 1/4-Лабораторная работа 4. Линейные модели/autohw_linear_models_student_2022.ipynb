{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 4. Линейные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые задачи в этом ноутбуке надо будет сдавать в [контест](https://contest.yandex.ru/contest/40818/enter). Когда сдаете туда код, не забудьте сверху прописать все нужные импорты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы рассчитываем, что перед тем, как садиться за этот ноутбук, вы прослушали лекции про МНК, регрессию и регуляризацию или прочитали часть про регрессию главы \"Линейные модели\" ШАДовского учебника по ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с загрузки необходимых библиотек и функций.\n",
    "\n",
    "Параметр `seed` будет использоваться далее для инициализации генератора случайных чисел из библиотеки `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, List\n",
    "\n",
    "import sklearn.base\n",
    "\n",
    "seed = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке мы будем практиковаться на датасете [\"The Ames Iowa Housing Data\"](https://www.openml.org/d/41211). Здесь собраны описания и цены жилья в городе Эймс, штат Айова. Мы будем решать задачу предсказания цены (`Sale_Price`) по всем остальным признакам.\n",
    "\n",
    "И начнём мы, конечно, с того, что внимательно посмотрим на датасет: какие там есть объекты и какие признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100 1646k    0 1646k    0     0  1273k      0 --:--:--  0:00:01 --:--:-- 1282k\r\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the line below to download data and install necessary packages\n",
    "# Maybe won't work on Windows :(\n",
    "\n",
    "# !pip install numpy pandas sklearn matplotlib\n",
    "!curl https://api.openml.org/data/get_csv/20649135/file2ed11cebe25.arff > data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                               MS_SubClass                     MS_Zoning  \\\n1135   One_Story_1946_and_Newer_All_Styles       Residential_Low_Density   \n936                    Split_or_Multilevel       Residential_Low_Density   \n1353  One_and_Half_Story_Finished_All_Ages       Residential_Low_Density   \n2787   One_Story_1946_and_Newer_All_Styles       Residential_Low_Density   \n2509          Two_Story_PUD_1946_and_Newer  Floating_Village_Residential   \n\n      Lot_Frontage  Lot_Area Street            Alley           Lot_Shape  \\\n1135            66     13695   Pave  No_Alley_Access             Regular   \n936              0     13607   Pave  No_Alley_Access  Slightly_Irregular   \n1353            60      9144   Pave            Paved             Regular   \n2787            60      7200   Pave  No_Alley_Access             Regular   \n2509            30      3180   Pave            Paved             Regular   \n\n     Land_Contour Utilities Lot_Config  ...            Fence Misc_Feature  \\\n1135          Lvl    AllPub     Inside  ...         No_Fence         None   \n936           Lvl    AllPub     Inside  ...         No_Fence         Shed   \n1353          Lvl    AllPub     Inside  ...         No_Fence         None   \n2787          Low    AllPub     Inside  ...  Minimum_Privacy         None   \n2509          Lvl    AllPub     Inside  ...         No_Fence         None   \n\n     Misc_Val Mo_Sold Year_Sold Sale_Type Sale_Condition Sale_Price  \\\n1135        0       6      2008       WD          Normal     159000   \n936      1500       4      2009       WD          Normal     208000   \n1353        0       3      2008       WD          Normal     162500   \n2787        0       3      2006       WD          Normal     119900   \n2509        0       4      2006       WD         Abnorml     144152   \n\n      Longitude   Latitude  \n1135 -93.690761  42.037806  \n936  -93.644864  42.010636  \n1353 -93.625539  42.028274  \n2787 -93.682979  42.020998  \n2509 -93.644891  42.047595  \n\n[5 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MS_SubClass</th>\n      <th>MS_Zoning</th>\n      <th>Lot_Frontage</th>\n      <th>Lot_Area</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>Lot_Shape</th>\n      <th>Land_Contour</th>\n      <th>Utilities</th>\n      <th>Lot_Config</th>\n      <th>...</th>\n      <th>Fence</th>\n      <th>Misc_Feature</th>\n      <th>Misc_Val</th>\n      <th>Mo_Sold</th>\n      <th>Year_Sold</th>\n      <th>Sale_Type</th>\n      <th>Sale_Condition</th>\n      <th>Sale_Price</th>\n      <th>Longitude</th>\n      <th>Latitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1135</th>\n      <td>One_Story_1946_and_Newer_All_Styles</td>\n      <td>Residential_Low_Density</td>\n      <td>66</td>\n      <td>13695</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Regular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>No_Fence</td>\n      <td>None</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>159000</td>\n      <td>-93.690761</td>\n      <td>42.037806</td>\n    </tr>\n    <tr>\n      <th>936</th>\n      <td>Split_or_Multilevel</td>\n      <td>Residential_Low_Density</td>\n      <td>0</td>\n      <td>13607</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Slightly_Irregular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>No_Fence</td>\n      <td>Shed</td>\n      <td>1500</td>\n      <td>4</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208000</td>\n      <td>-93.644864</td>\n      <td>42.010636</td>\n    </tr>\n    <tr>\n      <th>1353</th>\n      <td>One_and_Half_Story_Finished_All_Ages</td>\n      <td>Residential_Low_Density</td>\n      <td>60</td>\n      <td>9144</td>\n      <td>Pave</td>\n      <td>Paved</td>\n      <td>Regular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>No_Fence</td>\n      <td>None</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>162500</td>\n      <td>-93.625539</td>\n      <td>42.028274</td>\n    </tr>\n    <tr>\n      <th>2787</th>\n      <td>One_Story_1946_and_Newer_All_Styles</td>\n      <td>Residential_Low_Density</td>\n      <td>60</td>\n      <td>7200</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Regular</td>\n      <td>Low</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>Minimum_Privacy</td>\n      <td>None</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>119900</td>\n      <td>-93.682979</td>\n      <td>42.020998</td>\n    </tr>\n    <tr>\n      <th>2509</th>\n      <td>Two_Story_PUD_1946_and_Newer</td>\n      <td>Floating_Village_Residential</td>\n      <td>30</td>\n      <td>3180</td>\n      <td>Pave</td>\n      <td>Paved</td>\n      <td>Regular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>No_Fence</td>\n      <td>None</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>144152</td>\n      <td>-93.644891</td>\n      <td>42.047595</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 81 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data.csv')\n",
    "\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 81 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   MS_SubClass         2930 non-null   object \n",
      " 1   MS_Zoning           2930 non-null   object \n",
      " 2   Lot_Frontage        2930 non-null   int64  \n",
      " 3   Lot_Area            2930 non-null   int64  \n",
      " 4   Street              2930 non-null   object \n",
      " 5   Alley               2930 non-null   object \n",
      " 6   Lot_Shape           2930 non-null   object \n",
      " 7   Land_Contour        2930 non-null   object \n",
      " 8   Utilities           2930 non-null   object \n",
      " 9   Lot_Config          2930 non-null   object \n",
      " 10  Land_Slope          2930 non-null   object \n",
      " 11  Neighborhood        2930 non-null   object \n",
      " 12  Condition_1         2930 non-null   object \n",
      " 13  Condition_2         2930 non-null   object \n",
      " 14  Bldg_Type           2930 non-null   object \n",
      " 15  House_Style         2930 non-null   object \n",
      " 16  Overall_Qual        2930 non-null   object \n",
      " 17  Overall_Cond        2930 non-null   object \n",
      " 18  Year_Built          2930 non-null   int64  \n",
      " 19  Year_Remod_Add      2930 non-null   int64  \n",
      " 20  Roof_Style          2930 non-null   object \n",
      " 21  Roof_Matl           2930 non-null   object \n",
      " 22  Exterior_1st        2930 non-null   object \n",
      " 23  Exterior_2nd        2930 non-null   object \n",
      " 24  Mas_Vnr_Type        2930 non-null   object \n",
      " 25  Mas_Vnr_Area        2930 non-null   int64  \n",
      " 26  Exter_Qual          2930 non-null   object \n",
      " 27  Exter_Cond          2930 non-null   object \n",
      " 28  Foundation          2930 non-null   object \n",
      " 29  Bsmt_Qual           2930 non-null   object \n",
      " 30  Bsmt_Cond           2930 non-null   object \n",
      " 31  Bsmt_Exposure       2930 non-null   object \n",
      " 32  BsmtFin_Type_1      2930 non-null   object \n",
      " 33  BsmtFin_SF_1        2930 non-null   int64  \n",
      " 34  BsmtFin_Type_2      2930 non-null   object \n",
      " 35  BsmtFin_SF_2        2930 non-null   int64  \n",
      " 36  Bsmt_Unf_SF         2930 non-null   int64  \n",
      " 37  Total_Bsmt_SF       2930 non-null   int64  \n",
      " 38  Heating             2930 non-null   object \n",
      " 39  Heating_QC          2930 non-null   object \n",
      " 40  Central_Air         2930 non-null   object \n",
      " 41  Electrical          2930 non-null   object \n",
      " 42  First_Flr_SF        2930 non-null   int64  \n",
      " 43  Second_Flr_SF       2930 non-null   int64  \n",
      " 44  Low_Qual_Fin_SF     2930 non-null   int64  \n",
      " 45  Gr_Liv_Area         2930 non-null   int64  \n",
      " 46  Bsmt_Full_Bath      2930 non-null   int64  \n",
      " 47  Bsmt_Half_Bath      2930 non-null   int64  \n",
      " 48  Full_Bath           2930 non-null   int64  \n",
      " 49  Half_Bath           2930 non-null   int64  \n",
      " 50  Bedroom_AbvGr       2930 non-null   int64  \n",
      " 51  Kitchen_AbvGr       2930 non-null   int64  \n",
      " 52  Kitchen_Qual        2930 non-null   object \n",
      " 53  TotRms_AbvGrd       2930 non-null   int64  \n",
      " 54  Functional          2930 non-null   object \n",
      " 55  Fireplaces          2930 non-null   int64  \n",
      " 56  Fireplace_Qu        2930 non-null   object \n",
      " 57  Garage_Type         2930 non-null   object \n",
      " 58  Garage_Finish       2930 non-null   object \n",
      " 59  Garage_Cars         2930 non-null   int64  \n",
      " 60  Garage_Area         2930 non-null   int64  \n",
      " 61  Garage_Qual         2930 non-null   object \n",
      " 62  Garage_Cond         2930 non-null   object \n",
      " 63  Paved_Drive         2930 non-null   object \n",
      " 64  Wood_Deck_SF        2930 non-null   int64  \n",
      " 65  Open_Porch_SF       2930 non-null   int64  \n",
      " 66  Enclosed_Porch      2930 non-null   int64  \n",
      " 67  Three_season_porch  2930 non-null   int64  \n",
      " 68  Screen_Porch        2930 non-null   int64  \n",
      " 69  Pool_Area           2930 non-null   int64  \n",
      " 70  Pool_QC             2930 non-null   object \n",
      " 71  Fence               2930 non-null   object \n",
      " 72  Misc_Feature        2930 non-null   object \n",
      " 73  Misc_Val            2930 non-null   int64  \n",
      " 74  Mo_Sold             2930 non-null   int64  \n",
      " 75  Year_Sold           2930 non-null   int64  \n",
      " 76  Sale_Type           2930 non-null   object \n",
      " 77  Sale_Condition      2930 non-null   object \n",
      " 78  Sale_Price          2930 non-null   int64  \n",
      " 79  Longitude           2930 non-null   float64\n",
      " 80  Latitude            2930 non-null   float64\n",
      "dtypes: float64(2), int64(33), object(46)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьём данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (2344, 80) (2344,)\n",
      "Test : (586, 80) (586,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_column = \"Sale_Price\"\n",
    "np.random.seed(seed)\n",
    "\n",
    "test_size = 0.2\n",
    "data_train, data_test, Y_train, Y_test = train_test_split(\n",
    "    data[data.columns.drop(\"Sale_Price\")],\n",
    "    np.array(data[\"Sale_Price\"]),\n",
    "    test_size=test_size,\n",
    "    random_state=seed)\n",
    "\n",
    "print(f\"Train : {data_train.shape} {Y_train.shape}\")\n",
    "print(f\"Test : {data_test.shape} {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди признаков нам встретятся как вещественные, так и категориальные. Пока что выделим в качестве категориальных те, значениями которых являются не числа, а какие-то другие сущности (но имейте в виду, что численные с виду признаки тоже могут быть категориальными)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous : 34, Categorical : 46\n"
     ]
    }
   ],
   "source": [
    "continuous_columns = [key for key in data.keys() if data[key].dtype in (\"int64\", \"float64\")]\n",
    "categorical_columns = [key for key in data.keys() if data[key].dtype == \"object\"]\n",
    "\n",
    "continuous_columns.remove(target_column)\n",
    "\n",
    "print(f\"Continuous : {len(continuous_columns)}, Categorical : {len(categorical_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на заголовки признаков. В целом, многие названия вполне говорящие, и можно догадаться, что стоит за этими признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['Lot_Frontage',\n 'Lot_Area',\n 'Year_Built',\n 'Year_Remod_Add',\n 'Mas_Vnr_Area',\n 'BsmtFin_SF_1',\n 'BsmtFin_SF_2',\n 'Bsmt_Unf_SF',\n 'Total_Bsmt_SF',\n 'First_Flr_SF',\n 'Second_Flr_SF',\n 'Low_Qual_Fin_SF',\n 'Gr_Liv_Area',\n 'Bsmt_Full_Bath',\n 'Bsmt_Half_Bath',\n 'Full_Bath',\n 'Half_Bath',\n 'Bedroom_AbvGr',\n 'Kitchen_AbvGr',\n 'TotRms_AbvGrd',\n 'Fireplaces',\n 'Garage_Cars',\n 'Garage_Area',\n 'Wood_Deck_SF',\n 'Open_Porch_SF',\n 'Enclosed_Porch',\n 'Three_season_porch',\n 'Screen_Porch',\n 'Pool_Area',\n 'Misc_Val',\n 'Mo_Sold',\n 'Year_Sold',\n 'Longitude',\n 'Latitude']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из целей этого ноутбука — познакомить вас с fit-predict (fit-transform) интерфейсом, типичным для многих реализаций моделей машинного обучения и для различных инструментов работы с данными.\n",
    "\n",
    "Множество фреймворков машинного обучения (например, scikit-learn, CatBoost) содержат в себе модели и алгоритмы, которые описаны в виде классов, у которых есть два ключевых метода: fit и predict (transform). Давайте разберёмся, что делают эти методы.\n",
    "\n",
    "***fit*** — метод для обучения алгоритма. Он получает на входе данные и таргеты для обучения, после чего обновляет состояние класса. После использования метода fit считается, что объект класса готов к использованию. Внутри этого метода может быть что угодно: обучение модели, подбор гиперпараметров, подсчет статистик и т. д.\n",
    "\n",
    "***predict*** — метод для предсказания , обученного с помощью _fit_. В задаче регрессии это оценка параметра, в задаче классификации предсказанный класс.\n",
    "\n",
    "***transform*** — стилистический синоним _predict_, но используется в классах, которые реализуют преобразования данных, например, масштабирование признаков или кодирование категориальных фичей.\n",
    "\n",
    "***fit_transform*** — метод который учится на данных, а потом их же преобразовывает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                              MS_SubClass                MS_Zoning  \\\n2753  One_Story_1946_and_Newer_All_Styles  Residential_Low_Density   \n2248                          Split_Foyer  Residential_Low_Density   \n1924  One_Story_1946_and_Newer_All_Styles  Residential_Low_Density   \n49           One_Story_PUD_1946_and_Newer  Residential_Low_Density   \n621   One_Story_1946_and_Newer_All_Styles  Residential_Low_Density   \n\n      Lot_Frontage  Lot_Area Street            Alley           Lot_Shape  \\\n2753            64      6762   Pave  No_Alley_Access             Regular   \n2248             0      7540   Pave  No_Alley_Access  Slightly_Irregular   \n1924            80      9736   Pave  No_Alley_Access             Regular   \n49              41      7132   Pave  No_Alley_Access  Slightly_Irregular   \n621             80      9600   Pave  No_Alley_Access             Regular   \n\n     Land_Contour Utilities Lot_Config  ...            Fence Misc_Feature  \\\n2753          Lvl    AllPub     Inside  ...         No_Fence         None   \n2248          Lvl    AllPub    CulDSac  ...  Minimum_Privacy         None   \n1924          Lvl    AllPub     Inside  ...         No_Fence         None   \n49            Lvl    AllPub     Inside  ...         No_Fence         None   \n621           Lvl    AllPub     Inside  ...         No_Fence         None   \n\n     Misc_Val Mo_Sold Year_Sold Sale_Type Sale_Condition Sale_Price  \\\n2753        0       7      2006       New        Partial     193879   \n2248        0       6      2007       WD          Normal     156000   \n1924        0       4      2007       WD          Normal     174850   \n49          0       4      2010       WD          Normal     205000   \n621         0       7      2009       WD          Normal     147000   \n\n      Longitude   Latitude  \n2753 -93.691234  42.024615  \n2248 -93.606672  41.994207  \n1924 -93.612347  42.043952  \n49   -93.649447  42.058252  \n621  -93.622494  42.036178  \n\n[5 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MS_SubClass</th>\n      <th>MS_Zoning</th>\n      <th>Lot_Frontage</th>\n      <th>Lot_Area</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>Lot_Shape</th>\n      <th>Land_Contour</th>\n      <th>Utilities</th>\n      <th>Lot_Config</th>\n      <th>...</th>\n      <th>Fence</th>\n      <th>Misc_Feature</th>\n      <th>Misc_Val</th>\n      <th>Mo_Sold</th>\n      <th>Year_Sold</th>\n      <th>Sale_Type</th>\n      <th>Sale_Condition</th>\n      <th>Sale_Price</th>\n      <th>Longitude</th>\n      <th>Latitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2753</th>\n      <td>One_Story_1946_and_Newer_All_Styles</td>\n      <td>Residential_Low_Density</td>\n      <td>64</td>\n      <td>6762</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Regular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>No_Fence</td>\n      <td>None</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2006</td>\n      <td>New</td>\n      <td>Partial</td>\n      <td>193879</td>\n      <td>-93.691234</td>\n      <td>42.024615</td>\n    </tr>\n    <tr>\n      <th>2248</th>\n      <td>Split_Foyer</td>\n      <td>Residential_Low_Density</td>\n      <td>0</td>\n      <td>7540</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Slightly_Irregular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>CulDSac</td>\n      <td>...</td>\n      <td>Minimum_Privacy</td>\n      <td>None</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>156000</td>\n      <td>-93.606672</td>\n      <td>41.994207</td>\n    </tr>\n    <tr>\n      <th>1924</th>\n      <td>One_Story_1946_and_Newer_All_Styles</td>\n      <td>Residential_Low_Density</td>\n      <td>80</td>\n      <td>9736</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Regular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>No_Fence</td>\n      <td>None</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>174850</td>\n      <td>-93.612347</td>\n      <td>42.043952</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>One_Story_PUD_1946_and_Newer</td>\n      <td>Residential_Low_Density</td>\n      <td>41</td>\n      <td>7132</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Slightly_Irregular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>No_Fence</td>\n      <td>None</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>205000</td>\n      <td>-93.649447</td>\n      <td>42.058252</td>\n    </tr>\n    <tr>\n      <th>621</th>\n      <td>One_Story_1946_and_Newer_All_Styles</td>\n      <td>Residential_Low_Density</td>\n      <td>80</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>No_Alley_Access</td>\n      <td>Regular</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>No_Fence</td>\n      <td>None</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>147000</td>\n      <td>-93.622494</td>\n      <td>42.036178</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 81 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lot_Frontage\n",
      "[141  80  81  93  74  78  41  43  39  60  75   0  63  85  47 152  88 140\n",
      " 105  65  70  26  21  53  24 102  98  83  94  95  90  79 100  44 110  61\n",
      "  36  67 108  59  92  58  56  73  72  84  76  50  55  68 107  25  30  57\n",
      "  40  77 120 137  87 119  64  96  71  69  52  51  54  86 124  82  38  48\n",
      "  89  66  45  35 129  31  42  28  99 104  97 103  34 117 149 122  62 174\n",
      " 106 112  32 115 128  91  33 121 144 130 109 150 113 125 101  46 114 135\n",
      " 136  37  22 313  49 123 160 195 118 134 182 116 138 155 126 200 168 111\n",
      " 131 153 133]\n",
      "Lot_Area\n",
      "[31770 11622 14267 ...  7937  8885 10441]\n",
      "Year_Built\n",
      "[1960 1961 1958 1968 1997 1998 2001 1992 1995 1999 1993 1990 1985 2003\n",
      " 1988 2010 1951 1978 1977 1974 2000 1970 1971 1975 2009 2007 2005 2004\n",
      " 2002 2006 1996 1994 2008 1980 1979 1984 1920 1965 1967 1963 1962 1976\n",
      " 1972 1966 1959 1964 1950 1952 1949 1940 1954 1955 1957 1956 1953 1948\n",
      " 1900 1910 1927 1915 1945 1929 1938 1923 1928 1890 1885 1922 1925 1939\n",
      " 1942 1936 1930 1921 1912 1917 1907 1875 1969 1947 1946 1987 1941 1924\n",
      " 1914 1931 1919 1989 1896 1973 1991 1981 1986 1916 1926 1935 1892 1898\n",
      " 1880 1882 1937 1902 1934 1982 1983 1932 1918 1904 1905 1872 1893 1906\n",
      " 1908 1911 1895 1879 1901 1913]\n",
      "Year_Remod_Add\n",
      "[1960 1961 1958 1968 1998 2001 1992 1996 1999 1994 2007 1990 1985 2003\n",
      " 2005 2010 1951 1988 1977 1974 2000 1970 2008 1971 1975 1978 2006 2004\n",
      " 2002 1995 2009 1980 1979 1984 1981 1950 1967 1963 1993 1966 1959 1964\n",
      " 1954 1972 1989 1957 1956 1952 1955 1962 1997 1965 1969 1987 1976 1991\n",
      " 1973 1986 1983 1953 1982]\n",
      "Mas_Vnr_Area\n",
      "[ 112    0  108   20  603  350  119  480   81  180  504  492  381  162\n",
      "  200  450  256  226  615  240  168  760  128 1095  232  412  178  106\n",
      "   14   16  165  114  338  362  348   30  579   36  122  130   31  250\n",
      "  120  216  432 1159  289   28   42  172  451  268   86  156  144  265\n",
      "  340  110  164  361  287  506  150  220  324   91  104  300  261  218\n",
      "  351  771  294   90   72   47  143  328  288   96  336  177   85  246\n",
      "   24   80  116  153  320  479  223  442  170  169  171  109   98  145\n",
      "  203  371  430   44  186  335   60   84  189  440  188   32  160   22\n",
      "   40   68   45  344  748  464  157  278  209  126  101  229  225  206\n",
      "  161  196  174  333   76  312  142  425  510  230  726  860  640  306\n",
      "  154  305  420  472  424  302  238  284  262  285  296  418  922  724\n",
      "  383  135  176  166  730  470  308  500  270  163   11  210  298  673\n",
      "  731  975  921  634  286  372  528  194  260  198  121  100  264  140\n",
      "  132  366  141  115  280  252  894  513  456  571  359  283  360  509\n",
      "   70   95  217    3  247  576  183  399  650  657  295  368   82  124\n",
      "  444   92   89   23   54  149  234  137  275  242  364  352  136  204\n",
      "  573  255   74  259   88  541  406  310  584  290  182   75  245  123\n",
      "  102  621  660  402  158  422  127  604  356   65  426  272  816  436\n",
      "  554  468  680  664  292 1110  221  766  616  714  146  318  647 1290\n",
      "  473  495  466  651  448   53  768   38  258  304  568  179  212 1050\n",
      "  564  342  148  243  491  237  410  151  187  387   52  125  276  415\n",
      "   39   41  299   99  190  251  281  227  202  396  134  192  205  215\n",
      "  113   50  266  147  222  796   58  632  668  228  219  674  197 1115\n",
      "  138  710  945   67  549  233  253  263  365  567  376  378  452  254\n",
      "  315  400  375  772  248  970  502  388  394  235  515  705 1170  594\n",
      "  309  526  754  208  428  353  105   57  337 1129 1600  600    1  525\n",
      "   66   63   56  224   87  291   69  279  435  323  167   51  214  519\n",
      "  438   48 1224  762  423  184  652  481  239  274  117  886  236   94\n",
      "  244  902  434   27  662  734  550 1031   34  514  408  380  297  370\n",
      "  385  788  562  870  518  572   18  322 1378  877  530  397  738  501\n",
      "  391  118   46  692  332  175   64  522 1047  379  207   97  532   62\n",
      "  199  355  459  405  327  257  293  653  630  382  443]\n",
      "BsmtFin_SF_1\n",
      "[2 6 1 3 7 4 5 0]\n",
      "BsmtFin_SF_2\n",
      "[   0  144 1120  163  168   78  119  121  117  859  981   42   46   81\n",
      " 1029  290  132  713  162  362  240  258  174  906  486  350  263 1073\n",
      "  692   12  159  712  668  474  453  684  387  688  972  127  252  334\n",
      "  232  480  590  284  276  472  239  180  294  622  495  539  479  113\n",
      " 1526  360  774  364  596  884  311   92  216  136   32  147 1127  466\n",
      "  630  201  345  512  230  247  661  620  202  483  750  690  105   60\n",
      "  352  102   95  465   63  262  500  670  768  393  286  450  177  764\n",
      "  344   72  243  420  210  694  875  507  435  419  250  116  354  820\n",
      "  624  273   76  270  110  288  411  228  186  449   48   93  438  613\n",
      "  852  555  841  799  811  842  382  182  456   80   64  336  306  308\n",
      "  374  872  108   52  196  128  488  319  532  106  169  608   41  606\n",
      "  645  492  181  956 1080 1063  391  380  531  723  491  120  679  612\n",
      "   40  125  279  400  208  193  823  287  175  604  153   35  619  139\n",
      "    6  351 1031 1037  176  829  211  264   38  206  167  580  543  219\n",
      "  259  404  468  138  955  691   66   96  149  154  442  448  227  546\n",
      "  398  469  722  761  627  529  522  873  891  755 1474  634  321  915\n",
      "  544  417  432  831  278  557  150  869 1020  530  904  499  215 1061\n",
      "  377  791  156 1393 1039  375  497 1057  526   68  402  748   28  165\n",
      "  184  281  912  600  506  373  551  982  441  682 1085  826  850 1164\n",
      " 1083  337  297  547  173  396  324  123]\n",
      "Bsmt_Unf_SF\n",
      "[ 441  270  406 ...   45 1503  239]\n",
      "Total_Bsmt_SF\n",
      "[1080  882 1329 ... 1381  757 1003]\n",
      "First_Flr_SF\n",
      "[1656  896 1329 ... 2028 1003 1389]\n",
      "Second_Flr_SF\n",
      "[   0  701  678  776  892  676 1589  672  860  504  567  601  707  563\n",
      "  862  630 1100  886  656 1151 1177  830 1122 1106  644 1185  783  956\n",
      " 1128  828  888  790  730  584 1098  823  840  600  636  804  756  720\n",
      "  550  873  754 1215  604  734  715  532  537 1169  505  546 1080  408\n",
      "  475  788  687  348  765  424  606  185  686 1111  622 1044  602  582\n",
      "  908  524  498  492  608  808 1074  780  662 1196  499  180  319  942\n",
      "  744  240  689  714  954  192  864  558  755  838  887 1523  614  800\n",
      "  878  703 1054  328  252  806  665 1788  772  748 1075 1152  358  380\n",
      "  430  880  700 1194 1070  915  912  576 1216  650  615  645  704  663\n",
      " 1275  670  631  833  684  809  785  779  978  988 1200  896 1134  868\n",
      " 1103  816  839  741  467  586 1174 1325  568 1088 1012  762 1295  728\n",
      "  745  742  876  716 1257  640  683 1276 1126 1032  793  695 1089 1038\n",
      " 1097 1304 1221 1140 1336 1067 1274  967 1017  871  858  920  981  438\n",
      " 1182  841  941 1209  897  591  786  702  918 1629  612  729  739  727\n",
      "  983  782  660 1369  972  855 1315  224  556  960  457  685  726  322\n",
      "  760  534 1296  368  768  629  813  406  548  517  455  496  690  994\n",
      " 1000  682  646  560  677  564 1063 1320  917  624  826  561  596  653\n",
      "  390  464  587  320  472  588  883  910  929 1040  784  462  649  425\n",
      "  611  747  769 1114 1120 1619  902  718  815  966  836  834  913  844\n",
      "  829 1116  573  885  926  977  807  738 1427  441  512  444  620  436\n",
      "  545  998  595  448  332  523 1240  516  668  928 1157  432  846  566\n",
      "  848 1020  717 1332 1370  857 1330  767 1420  866 1104  590 1237  898\n",
      " 1158 1162 1096 1139  884 1285  778 1160 1053  639 1061 1250 1093  904\n",
      " 1039  520  919  939  932 1028  843  861  842  794  825  850  893 1319\n",
      "  959  625  792  628  924 1345 1066  732 1540  933  832  453  220  384\n",
      "  412  510  182  501  581  375  680 1208  658  552  396 1818  797  540\n",
      "  308  973  691  539 1254  363  473  594  378  554  208  468  651  445\n",
      "  764  752  213  795  428  371  110  536  713  551  547  580  486 1051\n",
      "  511  872  648  527  495 1721 1099  735 1072  899  870  895  903 1141\n",
      " 1198  975  854  812  950  521  343  304  940 1611  811  673  442  890\n",
      " 1479  817  943  330  420  936  167  688  766  770 1342  900 1377  845\n",
      "  533 1402 1101  574 1036  570 1142 1238 1168  923  530  757 1048  796\n",
      " 1112 1131  694  750 2065 1288 1407 1171 1277 1872 1015 1306 1203  995\n",
      "  528  863 1426  925 1232 1357  743  976  761 1259 1008  984 1309  228\n",
      "  992  500  544 1778  299  616  831  664  494  642  659  671 1031  336\n",
      "  144  525  349  423 1164  356  698  245  592 1042  477 1005  971 1087\n",
      "  638  400  376 1121 1414 1362 1092  916  882  927  874  914  881  869\n",
      " 1242 1081  753  450 1133  674 1538  125 1440  787  531  585  514  775\n",
      "  589  979 1001  851 1178  351  957 1340 1349  712 1243  955  709  990\n",
      " 1384 1862 1371 1312 1405 1519 1392 1358  465 1347 1218 1060  466 1335\n",
      "  814  488 1321  482  711  930 1286  985 1029 1796 1368 1567 1189 1323\n",
      " 1234  798 1129  623  708  456  316 1360 1248  272  821  370 1007  518\n",
      "  476  502  867  661  297  679  875 1518  605  810  325  434  583  634\n",
      "  557  341  626 1836  541  454 1246  571 1037 1124 1045  989  827 1150\n",
      "  312  526  218  980  403  493  736  818  901  610  725  549 1175  697\n",
      "  439  360 1281 1230 1004]\n",
      "Low_Qual_Fin_SF\n",
      "[   0  390  362  144 1064  232  431  120  436  371  360  259  397  312\n",
      "  513  108  205  156  697  420  384  473  512  528  114  479  515   53\n",
      "   80  392  572  234  140  450  481  514]\n",
      "Gr_Liv_Area\n",
      "[1656  896 1329 ... 2028 2521 1003]\n",
      "Bsmt_Full_Bath\n",
      "[1 0 2 3]\n",
      "Bsmt_Half_Bath\n",
      "[0 1 2]\n",
      "Full_Bath\n",
      "[1 2 3 0 4]\n",
      "Half_Bath\n",
      "[0 1 2]\n",
      "Bedroom_AbvGr\n",
      "[3 2 1 4 6 5 0 8]\n",
      "Kitchen_AbvGr\n",
      "[1 2 3 0]\n",
      "TotRms_AbvGrd\n",
      "[ 7  5  6  8  4 12 10 11  9  3 13  2 15 14]\n",
      "Fireplaces\n",
      "[2 0 1 3 4]\n",
      "Garage_Cars\n",
      "[2 1 3 0 4 5]\n",
      "Garage_Area\n",
      "[ 528  730  312  522  482  470  582  506  608  442  440  420  393  841\n",
      "  492  834  400  500  546  663  480  304  525    0  511  264  320  308\n",
      "  751  772  606  868  532  678  820  484  958  756  576  474  430  437\n",
      "  433  434  779  962  527  712  671  486  666  880  676  614  750  618\n",
      "  463  462  457  476  429  539  336  280  260  461  564  762  713  588\n",
      "  496  852  592  475  596  535  660  441  490  504  517  240  364  244\n",
      "  315  578  620  447  294  531  263  318  305  246  392  330  720  360\n",
      "  551  379  220  780  288  416  624  923  560  363  200  572  180  516\n",
      "  672  349  365  231  450  270  299  591  533  690  436  586  366  467\n",
      "  209  460 1017  574  776  632  740  615  594  580  513  523  850  670\n",
      "  613  621  598  502  494  319  352  216  399  252  567  473  625  384\n",
      "  741  573  888  520  680  510  431  746  686  286  253  495  616  275\n",
      "  538  390  758  499  396  427  380  409  389  343  565 1166  435  544\n",
      "  529  479  542  478  581  552  583  902  477  345  656  786  754  840\n",
      "  890 1390  864  836  896  900  842 1020  932  640  908  927  856  700\n",
      "  738  862  644  968  886  871  626  949  685  649  701  550  397  432\n",
      "  554  394  658  410  810 1069  889  815  647  623  711  898  972  726\n",
      "  844  689  795  984  692  812  782 1043  438  628  845  555  788  559\n",
      "  465  612  732  300  524  704  561  641  642  540  784  497  515  630\n",
      "  498  768  472  610  549  645  368  505  418  338  271  792  530  514\n",
      "  509  297  350  884  230  281  907  483  210  162  324  256  273  287\n",
      "  357  424  456  207  192  250 1184  164  316  226  668  452  284  303\n",
      "  340  234  290  266  296  425  466 1138  826  860  846  904  702  662\n",
      "  569  577  493  622  605  444  600 1231  570  736  521  512  451  195\n",
      "  313  342  215  282  213  307  186  295  501  468  189  351  541  912\n",
      "  650  885  471  765  920  412  402  602  698  714  601  386  404  406\n",
      "  682  683  557  619  489 1314  439  787  774 1220  858  905  866  706\n",
      " 1150 1003  789  870 1052  944  388  428  398  403  696  687  938  839\n",
      "  983  783  691  830  824  851  603  648  936  562  673  575  627  276\n",
      "  636  545  469  464  831  267  283  205  377  292  458  301 1488  372\n",
      "  401  414  311  225  828  869  370  208  160  355  228  322  408  354\n",
      "  249  534  453 1348  874  811  558  328  725  715  543  595  508  721\n",
      "  548  814 1418  369  599  344 1014  924  356  487  185 1248  857  816\n",
      "  358  665  800  749  892  257  423  526  373  729 1110  556  724  481\n",
      "  585  488  684  367  818  928 1040  878  947  895  694 1174  728  843\n",
      "  916  872  876  631  617  454  813  925  804  806  832  455  752  933\n",
      " 1092  865  954  825  859  590 1025  744  566  518  611 1105  571  309\n",
      "  306  310  293  371 1200  254  184  374  331  224  217  261  323  638\n",
      "  739  332  719  833  894  796  674  747  242  597  748  639  579 1154\n",
      "  248  100  722  422  808  995 1041 1356  963  443  413  773  675  716\n",
      "  604  485  770 1085  853  708  753  899  426  807  959  803  760 1134\n",
      "  584 1053  449  688  757  326  568  353  791 1008  378  258  255  198\n",
      "  459  667  445  325  848  317  646  265  609  375  272  327  766  693\n",
      "  405]\n",
      "Wood_Deck_SF\n",
      "[ 210  140  393    0  212  360  237  157  483  192  503  325  113  349\n",
      "  240  203  275  173   26  144  168  220  238  196  120   36  100  146\n",
      "  288  180  668   23  186  132  283  169   80  635   28  353  370  121\n",
      "  416  296   32  198  160  280  133  223  277  224  228  352  227  366\n",
      "  117  263  301   42  252  250  264  364  414  218  222  657   84   51\n",
      "  106   54  135  221  306   12  344   56  406  379  226  335  496  290\n",
      "  268  336   44  450  156  105  367   71  316  365  188  331   60  257\n",
      "  116  272  141  112   30   68  128  375  328  174  182  200   96  261\n",
      "  431   22  287  129  162  269   48  201   52  256  232  342   63  322\n",
      "  178  233  474  448  225   40  171  216  185  108   87  260  147  150\n",
      "  404  382  319   99  184  125  165  248  114  230  170  172  208  231\n",
      "  148  143  300   24  298  340  517  297   70  205  195  158  462  502\n",
      "  115  501  371  235  294  312  321   78   85  164  110   55  289   66\n",
      "  324  126  187   74  181  266  244   45  189  509  302  243   64  131\n",
      "  476  234  400   73  154  123  486  276  392   72  215   58  262  202\n",
      "  253  194  576  356  327   92  136  329  279  176  292  467  119   90\n",
      "  305  124  270  308   33  138  303  214  152  550   16  411  209  358\n",
      "  320  495  236  385  145  155   97   20  122   98   25   38  426  355\n",
      "  490   88   76  418  265   49   57  204  311  102  511  409   50  307\n",
      "   81  424  339  403  278  211  139  149  259  736  134  183  314  213\n",
      "  161  318  428  670  282  315  362  245  219  390  167  407   35  130\n",
      "  104  460  286  239  255  193  159  402  455  500  206  190  333  284\n",
      "  285   14  521  380  127  646  142  386  405  546  118  242  291  166\n",
      "  274  439  536 1424  690  330  421   95  441  246  351  197  384  444\n",
      "  295  175  354  519  177  179   89  361  247  870  309  432    4  641\n",
      "  153  857   94   86  191   75  631  229  436  345  520  199   27  394\n",
      "   53   77  466  304  241  103  586  684  453  413  468  207  530  574\n",
      "  326  728]\n",
      "Open_Porch_SF\n",
      "[ 62   0  36  34  82 152  60  84  21  75  54  12 122 120  96  85  68  55\n",
      "  30 133  50  95  35  70  74 119  67 150 130  49  27  23 116  20  48 172\n",
      "  56  32  57  81  86 136  45 168 102 104 144  39 111 166  44 192 184  42\n",
      "  78 137  76  69  66 224  26  40  98  73  38  28  52  17 124 160 100 228\n",
      " 108  18 158  10  11 132  58  90  22  46 278  92  33  61  59  77  25 262\n",
      " 105  64 140 156 207  53  24 312  72  43  94  63 176 195 134 162 197 274\n",
      " 170 273 185 190 114 235 183  16  51 103 128 146 126 165 226 121 112 175\n",
      " 182 113  88 178  91  41  93 177 234 254 169 204  99  80 110 189 287 523\n",
      "  15 135 198 188 215 155 142 222 193  29 151 240 200 148 201 118 154 238\n",
      " 247 304 101 173 282 180  65 131 153  87 174 210 251 243 211 129   4 230\n",
      " 213 547 291 502 299 365 139 216  89 117 236   8 187 159 106 372 292 141\n",
      " 217 123  83 276 265 164 205 368  47 203 191 138 364 127 256 214 241 194\n",
      " 285 324 208 171 570 244 231 484 406 742 444 252 263 266  97  37 250 246\n",
      " 229  31 267 382 319 258   6 341 260 288 418 115 253 245 107 225 125 199]\n",
      "Enclosed_Porch\n",
      "[   0  170  184  154   80  220  186  156  120  112  150  164  189  205\n",
      "  113  216  135  130  202  126  334  246  196   18  158  114   60   41\n",
      "  128   35   48   32   64  364   40  318  248  168   45  239  176   77\n",
      "   52   56   36  136   96  242   42   86  162   98  265   50  280  222\n",
      "  144  209   24   91  236  218  228   84  264  260  240  203  140  252\n",
      "  100  134  432  198  116  169  148  244   25   81  102  160  386  226\n",
      "  238  115   94  208  105   54   51   34  268   30  213  288   90  192\n",
      "  177  211  185   55  180   44   57   78  137   72  368   70  165   92\n",
      "   16  123   66  210   68  109  194  139  219  259  212   20  101   87\n",
      "  117  204  122  108  190  231  138  183  254  301  121  207  224  172\n",
      "  174   99  249  291  145  214  275  290  175   26  143  230   88   39\n",
      " 1012   43  286   19  584  200  133  234   37  324  552  161   75  167\n",
      "   28  293  104  296  330  221  256  129  225  294  272  429   67  132\n",
      "   23]\n",
      "Three_season_porch\n",
      "[  0 238 224 144 508 168 255 225 360 162 140 150 182 153 320 174 304 216\n",
      " 407  96 245 120 219 180 196 176  86  23 290 323 130]\n",
      "Screen_Porch\n",
      "[  0 120 144 140 210 165 256 216  90 204 143 160 182 385 240 168 148  95\n",
      " 266 166 116 161 200 155 108 291 490 170 192 180 156 196 197 152 121  92\n",
      " 288 185 342 189 252 234 255 111 112 231  40 100  60 142 110 396 225 117\n",
      " 195 145 224 115 198 233 190 141 208  80 176  94 164 178 273 130 480 220\n",
      "  64 163 287 175 576 227 265 221 171 135 322 174 147 276 260 217 201 109\n",
      "  99 150 126 259 184  84 154  53 153 228 138 263  88 280 123 440 374 119\n",
      " 222 264 270  63 122 128 162 410 271 312 348 113 104]\n",
      "Pool_Area\n",
      "[  0 144 480 576 555 368 444 228 561 519 648 800 512 738]\n",
      "Misc_Val\n",
      "[    0 12500   500   700   400   450  1500   300   600  1200  3500  2000\n",
      "  2500    54    80   490   480   350   650   900   800   750  1400  6500\n",
      "  1150  1000  4500  3000   560  1300  8300 15500 17000  1512   455   460\n",
      "   620   420]\n",
      "Mo_Sold\n",
      "[ 5  6  4  3  1  2  7 10  8 11  9 12]\n",
      "Year_Sold\n",
      "[2010 2009 2008 2007 2006]\n",
      "Longitude\n",
      "[-93.619754  -93.619756  -93.6193873 ... -93.606847  -93.60019\n",
      " -93.599996 ]\n",
      "Latitude\n",
      "[42.054035 42.053014 42.052659 ... 41.988314 41.990921 41.989265]\n"
     ]
    }
   ],
   "source": [
    "for feat in continuous_columns:\n",
    "    print(feat)\n",
    "    print(data[feat].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Базовая предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим два важных свойства линейной регрессии:\n",
    "\n",
    "- строго говоря, она умеет работать только с вещественными признаками\n",
    "- если признаки имеют разный масштаб при сопоставимой важности, регрессия может проигнорировать те, что имеют меньший масштаб\n",
    "\n",
    "Первое соображение заставляет придумывать способы борьбы с категориальными признаками, и мы начнём с самого простого: проигнорируем их.\n",
    "\n",
    "Второе соображение приводит к необходимости приводить признаки к одному масштабу (\"нормализовать фичи\"). В `sklearn` для этого есть два основных класса:\n",
    "\n",
    "- [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) - в каждой колонке вычитает среднее и делит на стандартное отклонение.\n",
    "- [sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) - в каждой колонке вычитает минимальное значение и делит на разницу между минимальным и максимальным.\n",
    "\n",
    "Применяются они в соответствии с описанной выше философией. Например:\n",
    "\n",
    "```\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "Обратите внимание, что scaler настраивается на обучающей выборке (именно по ней вычисляются среднее и стандартное отклонение), а к тестовой он применяется с уже подсчитанными статистиками.\n",
    "\n",
    "**Вопрос**. А зачем? Почему бы не нормировать отдельно обучающую и тестовую выборку? Почему бы не настроить наш scaler на объединении двух выборок? Ведь благодаря большему количеству данных мы бы настроили его точнее!\n",
    "<p>\n",
    "<details>\n",
    "  <summary>Кликните, чтобы узнать ответ</summary>\n",
    "\n",
    "Если мы по-разному отнормируем обучающую и тестовую выборки, то нам будет весьма сложно применять модель, обученную на одной из них, к другой. Это просто не будет иметь физического смысла.\n",
    "\n",
    "Настраивать что-либо на тестовой выборке — это очень плохая идея. Тестовая выборка должна быть неким независимым мерилом качества наших усилий по предсказанию, а если мы разрешим информации о распределении признаков в тестовой выборке \"протечь\" в процесс обучения, то мы эту независимость испортим.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы решили делать преобразование данных, которое состоит в:\n",
    "\n",
    "- сохранении лишь непрерывных фичей;\n",
    "- нормализации этих фичей (давайте остановимся на [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html))\n",
    "\n",
    "В этом пункте вам нужно будет сделать класс такой предобработки данных, причём оформим мы его в виде класса с интерфейсом fit-transform.\n",
    "\n",
    "Несколько важных соображений:\n",
    "\n",
    "1. В прошлой лабораторной метод fit у нас ничего не возвращал, но правильнее сделать так, чтобы метод fit возвращал сам класс. В частности, это позволит нам писать model = model.fit().\n",
    "\n",
    "2. Первоначальный анализ данных удобно делать, когда они лежат в pd.DataFrame, т к у этого класса много методов, которые малым количеством телодвижений позволяют считать статистики и строить графики. Модели же проще учить, когда данные лежат в np.array, потому большое количество библиотек, где реализованы алгоритмы машинного обучения совместимы именно с numpy. Поэтому сделайте так, чтобы метод transform получал на вход pd.Dataframe, а возвращал np.array.\n",
    "\n",
    "3. В sklearn есть классы, от которых можно отнаследоваться, чтобы сделать класс с [fit-predict](https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin) или [fit-transform](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) интерфейсом. Это очень полезно, т к позволит вам в дальнейшем пользоваться методами [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) и подобными. В этом пункте отнаследуйтесь от второго.\n",
    "\n",
    "4. У метода __init__ должен быть параметр ```needed_columns=None```. Туда передается список колонок, которые нужно взять из датафрейме. Делать это надо в ```fit``` и ```transform```. В случае если если он равен None, то класс оставляет все колонки из исходного набора данных.\n",
    "\n",
    "5. Обратите внимание, что достаточно реализовать `fit` и `transform`, а метод `fit_transform` из них слепит родительский класс.\n",
    "\n",
    "**Готовый препроцессор вам нужно будет сдать в Контест**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional, List\n",
    "\n",
    "class BaseDataPreprocessor(TransformerMixin):\n",
    "    def __init__(self, needed_columns: Optional[List[str]]=None):\n",
    "        \"\"\"\n",
    "        :param needed_columns: if not None select these columns from the dataframe\n",
    "        \"\"\"\n",
    "        self.scaler = StandardScaler()\n",
    "        self.needed_columns = needed_columns\n",
    "\n",
    "    def fit(self, data: pd.DataFrame, *args):\n",
    "        \"\"\"\n",
    "        Prepares the class for future transformations\n",
    "        :param data: pd.DataFrame with all available columns\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        if self.needed_columns:\n",
    "            data = data[self.needed_columns]\n",
    "        self.scaler.fit(data)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Transforms features so that they can be fed into the regressors\n",
    "        :param data: pd.DataFrame with all available columns\n",
    "        :return: np.array with preprocessed features\n",
    "        \"\"\"\n",
    "        if self.needed_columns:\n",
    "            data = data[self.needed_columns]\n",
    "\n",
    "        return self.scaler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (1 балл)** Сдайте вашу реализацию в Контест, задача «Простая предобработка»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = BaseDataPreprocessor(needed_columns=continuous_columns)\n",
    "\n",
    "X_train = preprocessor.fit_transform(data_train)\n",
    "X_test = preprocessor.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Умная предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем сделать что-нибудь поинтереснее. Для того, чтобы будущие алгоритмы регрессии работали хорошо, они должны обучаться и предсказывать на информативных фичах. Зачастую оказывается гораздо продуктивнее потратить какое-то время на изучение предметной области и придумывание хороших фичей (feature engineering), нежели жадно перебирать все известные алгоритмы машинного обучения.\n",
    "В этом пункте попробуйте придумать новых фичей и написать новый класс предобработки данных, который их добавляет (а, возможно, и убирает ещё какие-то старые).\n",
    "\n",
    "В конце этого пункта в раскрывашке перечислены наши идеи относительно того, что можно было добавить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SmartDataPreprocessor(TransformerMixin):\n",
    "    def __init__(self, needed_columns: Optional[List[str]]=None):\n",
    "        \"\"\"\n",
    "        :param needed_columns: if not None select these columns from the dataframe\n",
    "        \"\"\"\n",
    "        self.scaler = StandardScaler()\n",
    "        self.needed_columns = needed_columns\n",
    "\n",
    "    def fit(self, data: pd.DataFrame, *args):\n",
    "        \"\"\"\n",
    "        Prepares the class for future transformations\n",
    "        :param data: pd.DataFrame with all available columns\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        if self.needed_columns:\n",
    "            data = data[self.needed_columns]\n",
    "        self.scaler.fit(data)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Transforms features so that they can be fed into the regressors\n",
    "        :param data: pd.DataFrame with all available columns\n",
    "        :return: np.array with preprocessed features\n",
    "        \"\"\"\n",
    "        if self.needed_columns:\n",
    "            data = data[self.needed_columns]\n",
    "\n",
    "        return self.scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = SmartDataPreprocessor(needed_columns=continuous_columns)\n",
    "\n",
    "X_train = preprocessor.fit_transform(data_train)\n",
    "X_test = preprocessor.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Пара простых идей. Кликните, когда будете готовы</summary>\n",
    "\n",
    "Например в датасете есть координаты квартиры, которые по идее сами по себе мало чего дают нашему регрессору. С другой стороны, по ним можно оценить центр города (или просто найти его на карте) и использовать в качестве фичи расстояние до центра города, которое может естественным образом влиять на цену жилья.\n",
    "\n",
    "Ещё может быть полезным почистить пропуски. И тут есть хитрость. Если вы просто вызовете data.info(), то вам покажется, что пропусков нет, но они могут приходить под разными обличьями. Например, у 490 объектов параметр Lot_Frontage (площадь фасада) равен нулю. Неожиданно, правда? Возможно, мы хотим эти нулевые значения заменить чем-нибудь, скажем, медианой.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте получим базовое решение (бейзлайн), чтобы потом с ним можно было сравниваться.\n",
    "\n",
    "Обучите линейную регрессию на обучающей выборке (которую мы подвергли преобразованию BaseDataPreprocessor). В библиотеке Sklearn есть релизация [без регуляризации](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression), [с L2-регуляризацией](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) и [с L1-регуляризацией](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso).\n",
    "\n",
    "Начнём с обычной регрессии. Получите предсказания на тестовых данных и оцените на них качество модели. В качестве метрики оценки качества возьмите [средний модуль отклонения](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) (mean absolute error, MAE). Как вам кажется, насколько хорошей вышла модель?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуйте L2-регуляризованную модель Ridge(). Какие значения метрик она даёт?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, регуляризация редко портит модель, но важно правильно подобрать коэффициент регуляризации. Как именно — поговорим дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Выбор метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средний модуль ошибки (MAE) — в целом довольно хорошая метрика для задачи регрессии, потому что ее довольно легко проинтерпретировать. Но с ней есть одна проблема: ошибиться на $ 10 000 $ USD в предсказании цены квартиры стоимостью $ 100 000 $ USD страшнее чем допустить такую ошибку в предсказании цены жилья за $ 700 000 $ USD. Иными словами более показательной метрикой будет не абсолютная  ошибка $ error_i = |y_i - \\hat{y_i}|$, а логарифм относительной ошибки $error_i = log \\frac{y_i}{\\hat{y_i}} $. Также давайте обычное усреднение по всем примерам в тестовой выборке заменим на среднеквадратичное $ \\frac{1}{N} \\sum_i^{test} {error_i} \\longrightarrow \\sqrt{\\frac{1}{N} \\sum_i^{test}{(error_i)^2}}$. Итоговая метрика получается равной:\n",
    "\n",
    "$$\n",
    "Metric = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (log(y_i) - log(\\hat{y_i}))^2}\n",
    "$$\n",
    "\n",
    "Логично? Да. Но возникает еще одна проблема. Логарифм нельзя брать от отрицательного числа. Бороться с этим можно двумя способами.\n",
    "- Случай когда отрицательное число затисалось в target-ax не очень разумен, т. к. цена на дом не может быть отрицательной. В этом случае стоит кинуть ошибку, чтобы пользователь этой функции еще раз перепроверил правильные ли таргеты он подает.\n",
    "- В целом, у нас нет гарантий того, что наша модель (например линейная) предсказывает только положительные числа. Брать логарифм от отрицательного числа не получится, но качество такой модели все еще надо оценить. Давайте все предсказания, которые меньше некоторого порога $ a_{min} $, заменять этим порогом ($ \\hat{y_i} \\longleftarrow max(\\hat{y_i}, a_{min}) $), после чего подавать их в метрику. Для прохождения тестов возьмите $ a_{min} = 1 $.\n",
    "\n",
    "**2. (1 балл) Реализуйте эту метрику и сдайте в контест**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_logarithmic_error(y_true, y_pred, a_min=1.):\n",
    "    # <Your code here>\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Логарифмирование таргета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще идея с логарифмированием таргета довольно хороша для этой задачи. Давайте посмотрим на распределение обычных и логарифмированных таргетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_target_distribution(Y_train, Y_test, ax, n_bins=20):\n",
    "    ax.hist(Y_train, bins=n_bins, label=\"train\", color=\"red\", alpha=0.3, density=True)\n",
    "    ax.hist(Y_test, bins=n_bins, label=\"test\", color=\"blue\", alpha=0.3, density=True)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "\n",
    "\n",
    "def plot_both_distributions(Y_train, Y_test):\n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, nrows=1, figsize=(15, 6))\n",
    "\n",
    "    plot_target_distribution(Y_train, Y_test, ax=ax0)\n",
    "    ax0.set_title(\"Standard\")\n",
    "\n",
    "    plot_target_distribution(np.log(Y_train), np.log(Y_test), ax=ax1)\n",
    "    ax1.set_title(\"Logarithmic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_both_distributions(Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, если прологарифмировать таргеты, то их распределение станет более похоже на гауссовское. Интуиция подсказывает, что линейная регрессия с MSE loss-функцией должна лучше учиться на таких таргетах.\n",
    "\n",
    "Попробуйте написать класс, который во время обучения логарифмирует таргет, а во время предсказания — наоборот, экспоненциирует. После чего обучите оба метода на обучающих данных и сравните значения метрик MAE и MSLE на тесте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что должно быть в этом классе:\n",
    "- Класс должен называться ```ExponentialLinearRegression```\n",
    "- Класс должен иметь такой же fit-predict интерфейс, как и было до этого. На вход он получает оригинальные X и Y, а уже внутри происходит логарифмирование или экспоненциирование.\n",
    "- Внутри этой модели будет работать [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). Хочется, чтобы этому классу можно было передавать аргументы инициализации с помощью *args и **kwargs\n",
    "- Чтобы потом этот класс можно было использовать в [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) в следующих пунктах, у него должны быть реализованы 5 методов\n",
    "    1. ```__init__(self, *args, **kwargs)``` - все полученные аргументы передаются дальше в Ridge.\n",
    "    2. ```fit(self, X, Y)``` - обучает класс, возвращает self.\n",
    "    3. ```predict(self, X)``` - делает предсказание.\n",
    "    4. ```get_params(deep=True)``` - возвращает dict с параметрами модели. Больще подробностей [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)\n",
    "    5. ```set_params(**params)``` - передает нужные параметры в модель. Больше подробносте [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)\n",
    "- Есть два подхода к тому как сделать все нужные методы:\n",
    "    - Отнаследоваться от класса Ridge и переопределить методы fit и predict, внутри вызывая super() от отцовского класса.\n",
    "    - Отнаследоваться от класса RegressorMixin и внутренним атрибутом класса сделать Ridge. Тогда все методы нужно будет писать руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ExponentialLinearRegression():\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "    def get_params(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def set_params(self, *args, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (1 балл) Реализуйте этот класс и сдайте в контест**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_regressor = Ridge()\n",
    "exponential_regressor = ExponentialLinearRegression()\n",
    "\n",
    "classic_regressor.fit(X_train, Y_train)\n",
    "exponential_regressor.fit(X_train, Y_train)\n",
    "\n",
    "classic_prediction = classic_regressor.predict(X_test)\n",
    "exponential_prediction = exponential_regressor.predict(X_test)\n",
    "\n",
    "print(f\"MAE  : Classic : {mean_absolute_error(Y_test, classic_prediction)}  Exponential : {mean_absolute_error(Y_test, exponential_prediction)}\")\n",
    "print(f\"MSLE : Classic : {root_mean_squared_logarithmic_error(Y_test, classic_prediction)} Exponential : {root_mean_squared_logarithmic_error(Y_test, exponential_prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда получается так, что разные обученные вами модели приводят к улучшению одних метрик и ухудшению других. Это абсолютно нормально и этому не надо удивляться.\n",
    "\n",
    "Также зачастую случается так, что прирост по метрике не очень большой. И вы можете захотеть убедиться, что это реальное улучшение, а не просто случайная флуктуация. Для этого можно использовать подсчёт метрики про кросс-валидации (подробнее о ней можно почитать в соответствующей [главе учебника](https://ml-handbook.ru/chapters/cross_validation/intro)). Суть метода в следующем:\n",
    "\n",
    "- мы разбиваем (случайным образом!) доступную нам выборку на $K$ (часто $K=5$) частей, которые называются _фолдами_\n",
    "- мы обучаем нашу модель $K$ раз, уча на всех фолдах, кроме одного, а на этом одном тестируя\n",
    "- мы получаем $K$ значений метрики, которые вместе дают нам лучшее представление о том, как ведёт себя модель на разных разбиениях на трейн и тест. В качестве итоговой метрики можно, к примеру, взять среднее полученных значений\n",
    "\n",
    "Сделать всё это можно с помощью обёртки [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), в которую можно подать модель, датасет и интересующую вас метрику. При этом оценку по кросс-валидации можно делать на всей доступной у вас выборке (ибо кросс-валидация уже включает разбиение на трейн и тест).\n",
    "\n",
    "Вычислите оценки MAE по кросс-валидации обычной (не регуляризованной) линейной регрессии и ExponentialLinearRegression на объединении обучающей и тестовой выборок. \n",
    "\n",
    "**4. (1 балл) Посчитайте и сдайте две оценки по кросс-валидации в Контест**.\n",
    "\n",
    "Обратите внимание, что параметр scoring — это не совсем функция-метрика, а немного более сложный объект, который можно соорудить, например, с помощью обёртки [make_scorer](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer).\n",
    "\n",
    "Также имейте в виду, что, вообще говоря, с дефолтным значением параметра `cv` кросс-валидация разбивает датасет на фолды детерминированным образом. Если вам нужно случайное разбиение, то в качестве cv стоит подать объект класса `sklearn.model_selection.KFold` или `sklearn.model_selection.StratifiedKFold`. Используйте\n",
    "\n",
    "```\n",
    "cv=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Также при написании кода для кросс-валидации вам может пригодиться знание о пайплайнах.\n",
    "\n",
    "Представьте ситуацию. Прошел месяц с того момента, как вы построили модель, а теперь вам надо дообучить её на новых данных и активно применять для предсказания. Если вы не позаботились об инфраструктуре, то вам придётся рыскать по всему ноутбуку в поисках того, как вы предобрабатывали данные, какую модель учили, обязательно что-нибудь забудете и будете очень страдать. Поэтому человечество придумало пайплайны, которые позволяют объединить предобработку данных и обучение модели в один класс - pipeline. Его можно писать самому, либо взять из sklearn ([link](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейную регрессию почти всегда можно улучшить с помощью регуляризации. Но при этом у нас возникает **гиперпараметр** — коэффициент регуляризации, и подбирать его нужно правильно. Более подробно о подборе гиперпараметров вы можете прочитать в соответствующей [главе учебника](https://ml-handbook.ru/chapters/hyperparameters_tuning/intro)), а пока мы разберём самые базовые подходы.\n",
    "\n",
    "В этой лабораторной вы познакомитесь с самым тривиальным способом — подбором по сетке. В данном случае это значит, что мы фиксируем несколько значений коэффициента регуляризации ```alpha``` и просто для каждого из них смотрим, что получится. Но важно отметить, что коэффициенты регуляризации стоит перебирать по _логарифмической_ сетке, например: `1e-2, 1e-1, 1, 1e+1, 1e+2`.\n",
    "\n",
    "Разобравшись, что перебирать, перейдём к вопросу о том, как оценивать. Есть два основных подхода:\n",
    "\n",
    "— Train-Val-Test split. Датасет делится на три части, на одной модели учатся, на другой подбираются гиперпараметры, на третьей считаются финальные метрики. Этот метод довольно шумный, зато быстрый.\n",
    "— Кроссвалидация. Она значительно дольше, но надёжней. В этом пункте мы воспользуемся именно ей.\n",
    "\n",
    "Возьмите класс [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) из scikit-learn и с его помощью подберите гиперпараметр ```alpha``` для линейной регрессии с L2-регуляризацией (соответствующий класс зовут Ridge). Возможно, для минимизации разных метрик (_root_mean_squared_logarithmic_error_ и _mean_absolute_error_) понадобятся разные значения гиперпараметров. Выберите из сетки ```np.logspace(-3, 3, num=7, base=10.)``` значение, которое максимизирует _root_mean_squared_logarithmic_error_ для _ExponentialLinearRegression_ и \n",
    "\n",
    "**5. (1 балл) Загрузите оптимальное значение коэффициента регуляризации в Контест**.\n",
    "\n",
    "Параметр `cv` оставьте дефолтным или возьмите `cv=5` (результат не поменяется). Будьте внимательны: по умолчанию `best_score_` у `GridSearchCV` - это _самое большое значение_. Чтобы не попасться в эту ловушку, обратите внимание на параметр `greater_is_better` функции `make_scorer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Линейная модель своими руками\n",
    "\n",
    "В этом разделе вы напишете собственный класс линейной модели, чтобы лучше разобраться, как работает обучение с помощью SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная модель делает предсказание по такой формуле:\n",
    "$$\n",
    "\\hat{y_i} = \\langle \\vec{w}, \\vec{x_i} \\rangle + b\n",
    "$$\n",
    "Здесь $\\vec{w}$ и b - обучаемые параметры. $\\vec{x_i}$ - вектор фичей данного примера.\n",
    "$\\vec{w}$ и b находятся из задачи минимизации лосс функции:\n",
    "\n",
    "$$\n",
    "\\vec{w}, b = {argmin}_{\\vec{w}, b}(L) \\ ; \\ L = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2 + \\lambda \\vec{w}^T\\vec{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачу минимизации лосс функции мы будем решать градиентным спуском. Для этого надо найти градиенты лосса по параметром модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla_b L = \\frac{2}{N} sum(X \\vec{w} + b - \\vec{y})\\\\\n",
    "\\nabla_{\\vec{w}} L = \\frac{2}{N} X^T(X \\vec{w} + b - \\vec{y}) + 2\\lambda \\vec{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте реализуем этот алгоритм ввиде класса с методами fit-predict.\n",
    "Что в нем должно быть:\n",
    "1. Класс должен называться ```SGDLinearRegressor```\n",
    "2. Класс должен быть отнаследован от sklearn-овского класса [RegressorMixin](https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html)\n",
    "3. Класс должен инициализироваться со следующими гиперпараметрами:\n",
    "\n",
    "    a. ```lr``` — learning rate. Длина шага градиентного спуска\n",
    "\n",
    "    b. ```regularization``` — коэффициент $\\lambda$ из формулы выше\n",
    "    \n",
    "    c. ```delta_converged``` — устанавливает условие окончание обучение. В тот момент когда норма разности весов на соседних шагах градиентного спуска меньше чем ```delta_converged``` алгоритм перкращает обновлять веса\n",
    "    \n",
    "    d. ```max_steps``` — максимальное число шагов градиентного спуска\n",
    "    \n",
    "    e. ```batch_size``` — размер батча\n",
    "\n",
    "4. Реализуйте **стохастический** градиентный спуск. На каждом шагу градиентного спуска должен формироваться батч размера ```batch_size``` из матрицы признаков. Это нужно для того чтобы алгоритм быстрее сходился. Батч может выбираться случайно на каждом шаге градиентного спуска, либо каждую эпоху можно перемешивать трейн выборку и итерироваться батчами по ней."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Обратите внимание при реализации SGD на следующие моменты (частые ошибки):\n",
    "* не перепутайте, какие коэффициенты в SGD стоят при самой функции потерь, а какие — при регуляризационном члене. Правильный вариант: $\\frac{\\alpha}{batch\\_size}$ при градиенте MSE, $\\alpha\\lambda$ при градиенте регуляризатора.\n",
    "* для остановки нужно сравнивать норму, а не ее квадрат\n",
    "* для правильного решения нужно не итерироваться по батчу,  а перемножать матрицы (иначе не зайдет по TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SGDLinearRegressor(RegressorMixin):\n",
    "    def __init__(self,\n",
    "                 lr=0.01, regularization=1., delta_converged=1e-2, max_steps=1000,\n",
    "                 batch_size=64):\n",
    "        self.lr = lr\n",
    "        self.regularization = regularization\n",
    "        self.max_steps = max_steps\n",
    "        self.delta_converged = delta_converged\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        # <Your code here>\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # <Your code here>\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check yourself\n",
    "\n",
    "model = SGDLinearRegressor()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "print(Y_test.shape, prediction.shape)\n",
    "print(\"MAE : \", mean_absolute_error(Y_test, prediction))\n",
    "print(\"Mean log : \", root_mean_squared_logarithmic_error(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В самом начале ноутбука мы отбросили категориальные фичи, хотя они могут помочь нам сделать модель лучше. Давайте же научимся ими пользоваться.\n",
    "\n",
    "Самый простой подход — это закодировать значения категориального признака числами, скажем, от $0$ до $C-1$, где $C$ — количество значений категориального признака. Иногда это может сработать, но для этого нужно, чтобы между значениями признака были определены отношения больше/меньше (такие признаки называются _ординальными_), причём соотношения между значениями должны быть более-менее линейными. В целом, не очень частая ситуация, поэтому так мы делать не будем.\n",
    "\n",
    "Вместо этого мы будем использовать OneHotEncoding. Пусть некоторая категориальная фича имеет $C$ уникальных значений. Давайте эту фичу закодируем в виде $C$ столбцов, каждый из которых соответствует некоторому уникальному значению категориальной фичи. Для каждого элемента выборки будем класть единичку в столбец, соответствующий этой фиче, и нолики в остальные.\n",
    "\n",
    "У этого метода есть недостаток. Если категориальная фича принимает слишком много значений, то вы нагенерируете много новых столбцов, каждый из которых будет содержать мало информации. Из-за них моделька может переобучиться.\n",
    "\n",
    "Этот метод имплементирован [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). У него есть пара важных гиперпараметров, которые стоит упомянуть:\n",
    "- ```handle_unknown``` - управляет обработкой незнакомых категорий на этапе `transform`. Число уникальных значений (и число столбцов) настраивается на обучающей выборке, и при дальнейшем применении может появиться значение, которого ещё не было. Если указать ```handle_unknown=\"ignore\"```, все поля для такого объекта будут заполнены нулями.\n",
    "- ```drop``` - если делать one-hot-encoding так как это описано выше, то сумма всех столбцов, соответствующих значениям категориальной фичи, будет равна единичному вектору. А такой вектор уже есть (он соответствует свободному члену). То есть признаки становятся линейно зависимыми, и это сломает процесс обучения линейной модели. Поэтому есть смысл для каждой фичи отбрасывать одну из получившихся колонок (```drop=\"first\"```) или хотя бы делать это только для бинарных фичей (```drop=\"if_binary\"```)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом пункте вам надо еще раз предобработать данные, добавив в них часть категориальных фичей, закодированных OneHotEncoding-ом. После этого обучите классификатор заново и выбейте лучшую метрику на тестовой выборке. А именно, мы добавим фичи \"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\". Используйте значение параметра handle_unknown=\"ignore\".\n",
    "\n",
    "*На практике в некоторых версиях scikit-learn есть проблема с совместимостью `handle_unknown=\"ignore\"` и `drop=\"first\"` одновременно, поэтому вторым можно пожертвовать.\n",
    "\n",
    "Класс будет наследоваться от BaseDataPreprocessor, так что в него можно будет передавать нужные для BaseDataPreprocessor параметры. Также это позволит не переписывать заново то, что происходит в базовом классе, а просто взывать к ним с помощью конструкции `super`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "interesting_columns = [\"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\"]\n",
    "\n",
    "class OneHotPreprocessor(BaseDataPreprocessor):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(OneHotPreprocessor, self).__init__(**kwargs)\n",
    "        ## <YOUR CODE HERE>\n",
    "\n",
    "    def fit(self, data, *args):\n",
    "        ## <YOUR CODE HERE>\n",
    "\n",
    "    def transform(self, data):\n",
    "        ## <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель с добавленными категориальными фичами. Получилось ли улучшить её качество?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представьте ситуацию. Прошел месяц с того момента, как вы построили модель, а теперь вам надо дообучить её на новых данных и активно применять для предсказания. Если вы не позаботились об инфраструктуре, то вам придётся рыскать по всему ноутбуку в поисках того, как вы предобрабатывали данные, какую модель учили, обязательно что-нибудь забудете и будете очень страдать. Поэтому человечество придумало пайплайны, которые позволяют объединить предобработку данных и обучение модели в один класс — pipeline. Его можно писать самому, либо взять из sklearn ([link](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)).\n",
    "\n",
    "**7. Напишите пайплайн, объединяющий использованную нами базовую предобработку данных (BaseDataPreprocessor и OneHotPreprocessor), а также линейную регрессию с L2-регуляризацией, и сдайте его в Контест.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_ultimate_pipeline():\n",
    "    # <YOUR CODE HERE>\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом пункте вы попробуете сделать что-то поинтереснее и загрузите плоды выших трудов в Контест.\n",
    "\n",
    "Попробуйте усовершенствовать предобработку данных, добавляя или выкидывая фичи, придумывая функции от признаков так, чтобы улучшить качество классификатора.\n",
    "\n",
    "Ещё несколько базовых идей о том, что можно было бы попробовать:\n",
    "\n",
    "- Постройте гистограммы значений признаков. Вы обнаружите, что некоторые из них почти всегда принимают одно и то же значение. Для начала их можно просто выкинуть.\n",
    "- Почистите выбросы. У некоторых объектов значения каких-то признаков могут сильно выбиваться, и это будет мешать регрессии обучиться. Вообще говоря, такие объекты можно выкидывать, но с текущей архитектурой пайплайна вам будет трудно это настроить. Так что вы можете пока заменять их на более разумные значения.\n",
    "- Мы добавили лишь несколько категориальных признаков, а на самом деле многие из них могут быть полезными.\n",
    "- Можно дискретизовать непрерывные фичи. Самый банальный пример: если непрерывная фича принимает всего несколько значений, её можно попробовать проинтерпретировать, как категориальную, и подать в one-hot энкодер. Но можно и как-то ещё разбивать по порогам.\n",
    "- Можно делать и более сложные преобразования. Например в датасете есть координаты квартиры, которые по идее сами по себе мало чего дают нашему регрессору. С другой стороны, по ним можно оценить центр города (или просто найти его на карте) и использовать в качестве фичи расстояние до центра города, которое может естественным образом влиять на цену жилья.\n",
    "- Не забывайте настраивать коэффициент регуляризации: для разных датасетов оптимальное значение будет разным.\n",
    "\n",
    "**В контест вам нужно будет сдать свой класс модели**. Он будет обучаться и тестироваться на новом и неизвестном вам разбиении датасета на трейн и тест по метрике `root_mean_squared_logarithmic_error`. За значение метрики 0.185 вы получите 1 балл (метрика будет округляться до трёх знаков после запятой). Для этого должно быть достаточно нормально написать OneHotPreprocessor и использовать ExponentialLinearRegression с правильно подобранным коэффициентом регуляризации. Если вам удалось получить метрику меньше, то вы получите\n",
    "\n",
    "`1 + min(1, (0.19 - x) / (0.19 - 0.15))`\n",
    "\n",
    "балла.\n",
    "\n",
    "В контесте будет специально проверено, что вы сдаёте именно `Pipeline`.\n",
    "\n",
    "Не забывайте, что вместе с пайплайном вам нужно отправить и все самописные классы, которые в нём участвуют.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}